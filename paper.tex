\documentclass[conference]{IEEEtran}
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{float}

\begin{document}

\title{Indonesian Car Retrieval System: An End-to-End Deep Learning Approach for Vehicle Detection and Type Classification}

\author{\IEEEauthorblockN{Author Name}
\IEEEauthorblockA{Institution Name\\
City, Country\\
email@example.com}}

\maketitle

\begin{abstract}
This paper presents a comprehensive Car Retrieval System designed for Indonesian vehicle detection and classification. The system integrates YOLOv8 object detection with a ResNet50-based classifier to identify eight distinct car types commonly found in Indonesia. Our approach achieves 86.33\% classification accuracy on a dataset of over 17,000 images spanning crossover, hatchback, MPV, offroad, pickup, sedan, truck, and van categories. The integrated pipeline processes video at 13.6 FPS, demonstrating real-time capability. Experimental results show strong per-class performance with F1-scores ranging from 0.83 to 0.91 across all vehicle categories. We provide a detailed analysis of the model's performance, including confusion matrix evaluation and per-class metric breakdowns, highlighting the system's robustness and identifying areas for future improvement.
\end{abstract}

\begin{IEEEkeywords}
Object Detection, Car Classification, Deep Learning, YOLOv8, ResNet50, Transfer Learning, Indonesian Vehicles
\end{IEEEkeywords}

\section{Introduction}

The rapid expansion of road networks and the increasing volume of vehicular traffic in Indonesia necessitate advanced intelligent transportation systems (ITS). Automated vehicle identification and classification are fundamental components of modern ITS, enabling applications such as electronic toll collection, traffic flow analysis, and law enforcement automation. In the Indonesian context, understanding the distribution and types of vehicles on roads is particularly crucial for traffic management and urban planning, given the unique vehicle composition of the region.

This paper addresses the specific challenge of developing an end-to-end car retrieval system tailored for the Indonesian automotive landscape. The primary objectives of this research are:
\begin{enumerate}
    \item To develop a robust object detection module capable of identifying multiple vehicle instances in complex visual environments, including static images and dynamic video streams.
    \item To implement a high-accuracy classification system that categorizes detected vehicles into eight specific Indonesian car types: crossover, hatchback, MPV, offroad, pickup, sedan, truck, and van.
    \item To integrate these components into a unified, real-time pipeline suitable for practical deployment scenarios.
\end{enumerate}

We propose a two-stage deep learning pipeline combining state-of-the-art object detection architecture with a custom-trained classification network. The YOLOv8 detector \cite{yolov8} is employed to localize vehicle regions with high speed and precision. Subsequently, a ResNet50-based classifier \cite{resnet}, optimized via transfer learning, determines the specific car type for each detected instance. This modular approach allows for independent optimization of detection and classification tasks, resulting in a flexible and high-performance system.

\section{Related Work}

\subsection{Object Detection}
The field of object detection has witnessed a paradigm shift from traditional computer vision techniques, such as Histogram of Oriented Gradients (HOG) combined with Support Vector Machines (SVM), to deep learning-based approaches. One-stage detectors, particularly the YOLO (You Only Look Once) family \cite{yolo}, have revolutionized real-time detection by framing the problem as a single regression task, mapping image pixels directly to bounding box coordinates and class probabilities. The latest iteration, YOLOv8, introduces significant architectural enhancements, including the C2f module for richer gradient flow and an anchor-free detection head, which further improves accuracy and inference speed, making it an ideal candidate for real-time traffic monitoring systems.

\subsection{Vehicle Classification}
Vehicle make and model recognition (VMMR) and type classification have been extensively studied using Convolutional Neural Networks (CNNs). Deep architectures like VGG, Inception, and ResNet \cite{resnet} have become the de facto standards for these tasks. ResNet, in particular, introduced residual connections that mitigate the vanishing gradient problem, enabling the training of substantially deeper networks. Transfer learning, where models pretrained on large-scale datasets like ImageNet \cite{imagenet} are fine-tuned on domain-specific data, has proven highly effective for vehicle classification tasks with limited labeled data. Recent works have also explored attention mechanisms and Vision Transformers (ViT) to capture fine-grained features, though CNNs remain widely used for their balance of performance and computational efficiency.

\section{Methodology}

\subsection{System Architecture}

Our proposed system architecture follows a sequential two-stage pipeline, maximizing the strengths of specialized models for detection and classification tasks. The workflow is illustrated in Figure \ref{fig:architecture}.

\begin{enumerate}
    \item \textbf{Detection Stage}: We utilize the YOLOv8-nano model, pretrained on the COCO dataset. This lightweight yet powerful model filters the input stream for vehicle-related classes (car, bus, truck), generating bounding boxes for all potential vehicle instances. The choice of the 'nano' variant ensures low latency, essential for video processing.
    \item \textbf{Preprocessing Stage}: Detected regions of interest (ROIs) are cropped from the original frame. These crops undergo preprocessing steps, including resizing to $224 \times 224$ pixels and normalization using ImageNet mean and standard deviation values, to prepare them for the classifier.
    \item \textbf{Classification Stage}: A ResNet50 model handles the type categorization. We modify the final fully connected layer to output probabilities for our eight specific target classes. The model takes the preprocessed vehicle crops and assigns a class label based on the highest confidence score.
\end{enumerate}

\begin{figure}[h]
\centering
\fbox{\parbox{0.9\columnwidth}{
\centering
Input Image \\ $\downarrow$ \\ \textbf{YOLOv8 Detection} \\ (Localization of Vehicles) \\ $\downarrow$ \\ \textbf{ROI Cropping \& Preprocessing} \\ (Resize to 224x224, Normalize) \\ $\downarrow$ \\ \textbf{ResNet50 Classification} \\ (Feature Extraction \& Prediction) \\ $\downarrow$ \\ \textbf{Final Output} \\ (Labeled Bounding Boxes)
}}
\caption{Detailed System Architecture showing the data flow from input to final annotated output.}
\label{fig:architecture}
\end{figure}

\subsection{Dataset Description}

The development and evaluation of our system rely on a comprehensive dataset of Indonesian vehicles. The dataset comprises 17,171 images distributed across eight distinct categories, representing the most common vehicle types on Indonesian roads. The distribution of the dataset is detailed in Table \ref{tab:dataset}.

\begin{table}[h]
\caption{Dataset Distribution across Train, Validation, and Test Splits}
\label{tab:dataset}
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Class} & \textbf{Train} & \textbf{Val} & \textbf{Test} & \textbf{Total} \\
\midrule
Crossover & 2,125 & 265 & 266 & 2,656 \\
Hatchback & 2,090 & 309 & 280 & 2,679 \\
MPV & 2,469 & 342 & 313 & 3,124 \\
Offroad & 1,919 & 240 & 240 & 2,399 \\
Pickup & 744 & 153 & 123 & 1,020 \\
Sedan & 1,961 & 284 & 255 & 2,500 \\
Truck & 659 & 83 & 82 & 824 \\
Van & 1,575 & 197 & 197 & 1,969 \\
\midrule
\textbf{Total} & \textbf{13,542} & \textbf{1,873} & \textbf{1,756} & \textbf{17,171} \\
\bottomrule
\end{tabular}
\end{table}

The dataset exhibits a slight class imbalance, with MPVs being the most dominant class (3,124 images) and Trucks being the least represented (824 images). This distribution reflects the real-world prevalence of these vehicle types in Indonesia.

\subsection{Classification Model Details}

For the classification task, we employ a ResNet50 architecture. The network is modified to adapt to our specific 8-class problem:
\begin{itemize}
    \item \textbf{Backbone}: The layers of ResNet50 up to the final global average pooling layer are used as a feature extractor. We initialize these layers with weights pretrained on ImageNet to leverage learned low-level features.
    \item \textbf{Classification Head}: We replace the original fully connected layer with a custom head consisting of:
    \begin{itemize}
        \item A Flatten layer.
        \item A Dropout layer with $p=0.5$ to prevent overfitting.
        \item A Linear layer mapping 2048 input features to 512 hidden units, followed by ReLU activation.
        \item A second Dropout layer ($p=0.25$).
        \item A final Linear layer mapping 512 units to the 8 output classes.
    \end{itemize}
\end{itemize}

\subsection{Training Strategy}

The model was trained using a rigorous setup to ensure optimal convergence and generalization. We employed the AdamW optimizer with $\beta_1=0.9$ and $\beta_2=0.999$, starting with a learning rate of $10^{-4}$. A Cosine Annealing learning rate scheduler was implemented to gradually reduce the learning rate to $10^{-6}$ over 20 epochs. To further improve robustness, we utilized Label Smoothing with a factor of 0.1, preventing the model from becoming overconfident in its predictions.

\textbf{Data Augmentation}: To address potential overfitting and improve the model's ability to handle diverse real-world conditions, we applied extensive data augmentation during training:
\begin{itemize}
    \item Random Resized Crop: To enforce scale invariance.
    \item Random Horizontal Flip: To handle orientation variations.
    \item Color Jitter: Random adjustments to brightness, contrast, saturation, and hue to simulate different lighting conditions.
    \item Random Rotation: Rotations up to $\pm 15^\circ$ to handle slight view angle changes.
    \item Random Erasing: To simulate occlusions.
\end{itemize}

\section{Experimental Results}

\subsection{Classification Performance}

The trained classifier was evaluated on the held-out test set containing 1,756 images. Table \ref{tab:results} summarizes the classification metrics for each class.

\begin{table}[h]
\caption{Detailed Classification Metrics on Test Set}
\label{tab:results}
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
\midrule
Crossover & 0.85 & 0.81 & 0.83 \\
Hatchback & 0.88 & 0.83 & 0.85 \\
MPV & 0.80 & 0.90 & 0.85 \\
Offroad & 0.86 & 0.85 & 0.86 \\
Pickup & 0.93 & 0.89 & 0.91 \\
Sedan & 0.87 & 0.87 & 0.87 \\
Truck & 0.92 & 0.88 & 0.90 \\
Van & 0.90 & 0.90 & 0.90 \\
\midrule
\textbf{Weighted Average} & \textbf{0.87} & \textbf{0.86} & \textbf{0.86} \\
\bottomrule
\end{tabular}
\end{table}

The model achieved an overall accuracy of \textbf{86.33\%}. The highest performance was observed in the 'Pickup' and 'Truck' categories, with F1-scores of 0.91 and 0.90 respectively. These vehicles typically possess distinct visual features (e.g., cargo beds) that make them easier to distinguish. Conversely, the 'Crossover' class yielded the lowest F1-score (0.83), likely due to its visual similarity to SUVs (categorized under Offroad) and Hatchbacks.

\subsection{Confusion Matrix Analysis}

To better understand the misclassifications, we analyzed the confusion matrix shown in Figure \ref{fig:confusion_matrix}.

\begin{figure}[H]
\centering
\includegraphics[width=\columnwidth]{outputs/evaluation/confusion_matrix.png}
\caption{Confusion Matrix of the Car Type Classifier on the Test Set. The diagonal elements represent correct predictions, while off-diagonal elements show misclassifications.}
\label{fig:confusion_matrix}
\end{figure}

The confusion matrix reveals specific patterns of error:
\begin{itemize}
    \item \textbf{MPV vs. Others}: While MPVs have a high recall (0.90), their precision is lower (0.80). The matrix indicates that other vehicle types, particularly Crossovers and Vans, are occasionally misclassified as MPVs. This is consistent with the visual ambiguity between these classes, as modern MPVs often share design traits with crossovers.
    \item \textbf{Crossover Confusion}: A notable number of Crossover vehicles are misclassified as MPVs or Hatchbacks. This supports the hypothesis that the definition of a 'Crossover' often overlaps visually with these other categories.
    \item \textbf{Sedan Robustness}: Sedans show balanced performance (0.87 Precision and Recall), indicating the model has learned robust features for this common vehicle type despite the high intra-class variance in sedan designs.
\end{itemize}

\subsection{Per-Class Metrics Visualization}

Figure \ref{fig:metrics} provides a visual comparison of Precision, Recall, and F1-Score across all classes.

\begin{figure}[H]
\centering
\includegraphics[width=\columnwidth]{outputs/evaluation/per_class_metrics.png}
\caption{Per-Class Classification Metrics (Precision, Recall, F1-Score) demonstrating consistent performance across categories.}
\label{fig:metrics}
\end{figure}

The visualization confirms that the model maintains a high standard of performance across the board, with no single class suffering from catastrophic failure. This consistency is crucial for a reliable retrieval system.

\subsection{Video Inference Evaluation}

The full integrated pipeline was tested on a real-world traffic video (\texttt{traffic\_test.mp4}, 197 seconds). The system processed 2,960 frames and generated the following statistics:
\begin{itemize}
    \item \textbf{Throughput}: Average processing speed of 13.6 FPS. While not fully real-time (often defined as 30 FPS), this speed is sufficient for many surveillance and offline analysis applications.
    \item \textbf{Latency}: Average inference time per frame was 73.7ms used a standard GPU environment.
    \item \textbf{Detections}: A total of 14,107 car instances were detected and classified.
    \item \textbf{Distribution}: The detected vehicle distribution was: MPV (34.7\%), Sedan (19.5\%), Hatchback (16.1\%), Offroad (12.0\%), Van (9.0\%), Pickup (4.1\%), Crossover (3.1\%), Truck (1.5\%). This aligns well with the expected distribution of vehicles on Indonesian roads, predominantly MPVs and city cars.
\end{itemize}

\section{Conclusion and Future Work}

We have successfully developed and validated a comprehensive Car Retrieval System tailored for the Indonesian context. By integrating a lightweight YOLOv8 detector with a robust ResNet50 classifier, we achieved an optimal balance between accuracy (86.33\%) and inference speed (13.6 FPS). The detailed error analysis highlighting confusion between visually similar classes like MPVs and Crossovers provides clear directions for future improvements.

\subsection{Future Work}
Several avenues for future research and improvement are identified:
\begin{itemize}
    \item \textbf{Fine-grained Classification}: Exploring Vision Transformers (ViT) or attention-based mechanisms to better distinguish between visually similar classes by focusing on specific discriminate parts of the vehicle (e.g., headlights, grilles).
    \item \textbf{Dataset Expansion}: augmenting the dataset with more samples of underrepresented classes like Trucks and Pickups to address class imbalance.
    \item \textbf{Edge Deployment}: Optimizing the models using quantization and pruning techniques (e.g., TensorRT, ONNX Runtime) to enable deployment on edge devices like NVIDIA Jetson for decentralized traffic monitoring.
    \item \textbf{Temporal Consistency}: Implementing tracking algorithms (e.g., DeepSORT) to smooth classifications over multiple video frames, reducing flickering predictions for the same vehicle instance.
\end{itemize}

\section*{Acknowledgment}

The authors would like to thank the providers of the Indonesian car image dataset for making this research possible.

\begin{thebibliography}{00}
\bibitem{yolov8} G. Jocher, A. Chaurasia, and J. Qiu, ``Ultralytics YOLO,'' 2023. [Online]. Available: https://github.com/ultralytics/ultralytics

\bibitem{yolo} J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, ``You Only Look Once: Unified, Real-Time Object Detection,'' in \textit{Proc. IEEE CVPR}, 2016, pp. 779--788.

\bibitem{resnet} K. He, X. Zhang, S. Ren, and J. Sun, ``Deep Residual Learning for Image Recognition,'' in \textit{Proc. IEEE CVPR}, 2016, pp. 770--778.

\bibitem{imagenet} J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, ``ImageNet: A Large-Scale Hierarchical Image Database,'' in \textit{Proc. IEEE CVPR}, 2009, pp. 248--255.

\bibitem{adamw} I. Loshchilov and F. Hutter, ``Decoupled Weight Decay Regularization,'' in \textit{ICLR}, 2019.
\end{thebibliography}

\end{document}
